{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "    div.text_cell_render, .CodeMirror pre, div.output {\n",
    "        font-size: 1.2em;\n",
    "        line-height: 1.2em;\n",
    "    }\n",
    "    .container {\n",
    "        width: 80%;\n",
    "    }\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poshmark Pipeline MVP\n",
    "\n",
    "The goal of this pipeline is to scrape data from Poshmark, process it, store it, and visualize it. \n",
    "\n",
    "1. Scrape listings for 10 brands\n",
    "2. Store using pickle\n",
    "3. Format data and engineer features\n",
    "4. Store using pickle\n",
    "5. Explore and visualize using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "from glob import glob\n",
    "from requests import get\n",
    "from datetime import datetime, date\n",
    "from time import sleep\n",
    "from functools import reduce\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil.parser import parse\n",
    "from inflection import parameterize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(filename='scraping.log', \n",
    "                    filemode='w', \n",
    "                    format='%(asctime)s - %(message)s', \n",
    "                    datefmt='%d-%b-%y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "HEADER = { 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36'}\n",
    "TODAY = date.today().strftime(\"%m_%d_%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to download web pages\n",
    "def download_page(url):\n",
    "    \"Download HTML source for a given URL\"\n",
    "    response = get(url, headers=HEADER)\n",
    "    return response\n",
    "\n",
    "def headless_download_page(url):\n",
    "    \"Download HTML source for the given city using a headless Firefox instance\"\n",
    "    options = Options()\n",
    "#     options.headless = True\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "    driver.get(url)\n",
    "    sleep(5)\n",
    "    html_text = driver.page_source\n",
    "    \n",
    "    return html_text\n",
    "\n",
    "def collect_pages(brand):\n",
    "    \"Collect all the pages for a given search query\"\n",
    "    count = 1\n",
    "    more_pages = True\n",
    "    pages = []\n",
    "\n",
    "    while more_pages:\n",
    "        url = f\"https://poshmark.com/brand/{brand}-Men-Jeans?availability=all&sort_by=added_desc&max_id={count}\"\n",
    "        print(url)\n",
    "        page = headless_download_page(url)\n",
    "        pages.append(page)\n",
    "        count += 1\n",
    "        sleep(5)\n",
    "        \n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        btns = soup.find_all('button', class_ = 'btn--pagination')\n",
    "\n",
    "        if btns[-1].has_attr('disabled'):\n",
    "            more_pages = False\n",
    "        \n",
    "        if count == 11:\n",
    "            more_pages = False\n",
    "        \n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to extract data from HTML\n",
    "def create_soup(source):\n",
    "    \"Convert HTML source to BeautifulSoup object\"\n",
    "    soup = BeautifulSoup(source, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def extract_tiles(soup):\n",
    "    \"Extract all the clothing tile elements\"\n",
    "    containers = soup.find_all('div', class_ = 'tile')\n",
    "    return containers\n",
    "\n",
    "def extract_title(tile):\n",
    "    \"Extract the title string from a tile\"\n",
    "    try:\n",
    "        title = tile.find('a', class_='tile__title').get_text(strip=True)\n",
    "    except:\n",
    "        title = ''\n",
    "        \n",
    "    return title\n",
    "\n",
    "def extract_status(tile):\n",
    "    \"Extract the status from a tile\"\n",
    "    try:\n",
    "        status = tile.find('span', class_='condition-tag').get_text(strip=True)\n",
    "    except:\n",
    "        status = ''\n",
    "        \n",
    "    return status\n",
    "\n",
    "def extract_stock(tile):\n",
    "    \"Extract the stock status from a tile\"\n",
    "    try:\n",
    "        stock = tile.find('i', class_='sold-tag').get_text(strip=True)\n",
    "    except:\n",
    "        stock = ''\n",
    "        \n",
    "    return stock\n",
    "\n",
    "def extract_price(tile):\n",
    "    \"Extract the price integer from a tile\"\n",
    "    try:\n",
    "        price = tile.find('span', attrs={'data-test': 'tile-price'}).get_text(strip=True)\n",
    "    except:\n",
    "        price = ''\n",
    "    \n",
    "    return price\n",
    "\n",
    "def extract_size(tile):\n",
    "    \"Extract the size integer from a tile\"\n",
    "    try:\n",
    "        size = tile.find('a', attrs={'data-test': 'tile-size'}).get_text(strip=True)\n",
    "    except:\n",
    "        size = ''\n",
    "    \n",
    "    return size\n",
    "\n",
    "def extract_brand(tile):\n",
    "    \"Extract the brand string from a tile\"\n",
    "    try:\n",
    "        brand = tile.find('a', attrs={'data-test': 'tile-brand'}).get_text(strip=True)\n",
    "    except:\n",
    "        brand = ''\n",
    "    \n",
    "    return brand\n",
    "\n",
    "def extract_link(tile):\n",
    "    \"Extract the link string from a tile\"\n",
    "    try:\n",
    "        link = tile.find('a', class_='tile__title').get('href')\n",
    "    except:\n",
    "        link = ''\n",
    "    \n",
    "    return link\n",
    "\n",
    "def extract_image(tile):\n",
    "    \"Extract the image link string from a tile\"\n",
    "    try:\n",
    "        image = tile.find('img').get('data-src')\n",
    "    except:\n",
    "        image = ''\n",
    "    \n",
    "    return image\n",
    "    \n",
    "def extract_date(url):\n",
    "    \"Extract the posting date from a url\"\n",
    "    \n",
    "    try:\n",
    "        start = url.find('20')\n",
    "        end = start + 10\n",
    "        date = url[start:end]\n",
    "    except:\n",
    "        date = ''\n",
    "    \n",
    "    return date\n",
    "\n",
    "def combine_data(tile):\n",
    "    \"Run independent functions and return object of all values\"\n",
    "    title = extract_title(tile)\n",
    "    status = extract_status(tile)\n",
    "    stock = extract_stock(tile)\n",
    "    price = extract_price(tile)\n",
    "    size = extract_size(tile)\n",
    "    brand = extract_brand(tile)\n",
    "    link = extract_link(tile)\n",
    "    image = extract_image(tile)\n",
    "    date = extract_date(image)\n",
    "        \n",
    "    return {\n",
    "        'title': title,\n",
    "        'status': status,\n",
    "        'stock': stock,\n",
    "        'price': price,\n",
    "        'size': size,\n",
    "        'brand': brand,\n",
    "        'link': link,\n",
    "        'image': image,\n",
    "        'date': date,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to format the data\n",
    "def format_price(price_value):\n",
    "    \"Remove extra text and convert to int\"\n",
    "    try:\n",
    "        price = int(price_value.replace('$', ''))\n",
    "    except:\n",
    "        price = np.nan\n",
    "        \n",
    "    return price\n",
    "\n",
    "def format_size(size_value):\n",
    "    \"Remove extra text and convert to int\"\n",
    "    try:    \n",
    "        size = int(size_value.replace('Size: ', ''))\n",
    "    except:\n",
    "        size = np.nan\n",
    "        \n",
    "    return size\n",
    "\n",
    "def format_brand(brand_value):\n",
    "    \"Make universal format\"\n",
    "    try:    \n",
    "        brand = parameterize(brand_value, '_')\n",
    "    except:\n",
    "        brand = ''\n",
    "        \n",
    "    return brand\n",
    "\n",
    "def format_link(link_value):\n",
    "    \"Add domain to link value\"\n",
    "    try:\n",
    "        link = 'http://www.poshmark.com' + link_value\n",
    "    except:\n",
    "        link = ''\n",
    "        \n",
    "    return link\n",
    "\n",
    "def format_date(date_value):\n",
    "    \"Convert string date to datetime\"\n",
    "    try:\n",
    "        date = parse(date_value)\n",
    "    except:\n",
    "        date = np.nan\n",
    "        \n",
    "    return date\n",
    "\n",
    "def format_record(record):\n",
    "    \"Format individual values of the record\"\n",
    "    record['price'] = format_price(record['price'])\n",
    "    record['size'] = format_size(record['size'])\n",
    "    record['brand'] = format_brand(record['brand'])\n",
    "    record['link'] = format_link(record['link'])\n",
    "    record['date'] = format_date(record['date'])\n",
    "    \n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to create new features\n",
    "def find_diff(date):\n",
    "    \"Find the amount of days an item has been listed\"\n",
    "    try:\n",
    "        now = datetime.now()\n",
    "        diff = abs((date-now).days)\n",
    "    except:\n",
    "        diff = np.nan\n",
    "        \n",
    "    return diff\n",
    "\n",
    "def calculate_length(title):\n",
    "    \"Find the length of the title\"\n",
    "    try:\n",
    "        length = len(title)\n",
    "    except:\n",
    "        length = np.nan\n",
    "    \n",
    "    return length\n",
    "\n",
    "def identify_condition(status):\n",
    "    \"Create boolean value for condition status\"\n",
    "    try:\n",
    "        condition = bool(status)\n",
    "    except:\n",
    "        condition = False\n",
    "    \n",
    "    return condition\n",
    "\n",
    "def check_stock(stock):\n",
    "    \"Create boolean value for stock status\"\n",
    "    try:\n",
    "        condition = bool(stock)\n",
    "    except:\n",
    "        condition = False\n",
    "    \n",
    "    return condition\n",
    "\n",
    "def create_features(record):\n",
    "    \"Create new features from record data\"\n",
    "    record['diff'] = find_diff(record['date'])\n",
    "    record['length'] = calculate_length(record['title'])\n",
    "    record['nwt'] = identify_condition(record['status'])\n",
    "    record['sold'] = check_stock(record['stock'])\n",
    "    \n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract raw data for multiple brands\n",
    "brands = [\n",
    "    'J._Crew', 'Naked_&_Famous_Denim', \"Levi's\", \n",
    "    'Diesel', 'Hugo_Boss', 'Mavi', 'Big_Star', \n",
    "    'Lucky_Brand', \"Joes's_Jeans\", 'True_Religion', \n",
    "    'Wrangler', 'Gap', 'Uniqlo'\n",
    "    ]\n",
    "\n",
    "for tag in brands:\n",
    "    print('Scraping', tag)\n",
    "    pages = collect_pages(tag)\n",
    "    soup_objs = [create_soup(page) for page in pages]\n",
    "    item_tiles = [extract_tiles(soup) for soup in soup_objs]\n",
    "    combined_tiles = reduce(lambda x,y: x+y, item_tiles)\n",
    "    item_objs = [combine_data(tile) for tile in combined_tiles]\n",
    "\n",
    "    brand_name = parameterize(tag, '_')\n",
    "    pickle.dump(item_objs, open(f\"./data/raw/{brand_name}_{TODAY}.p\", 'wb'))\n",
    "    logging.info(f\"Scraped {tag} page, found {len(item_objs)} items\")\n",
    "    \n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process raw data \n",
    "files = [file for file in glob(\"./data/raw/*.p\")]\n",
    "\n",
    "for f in files:\n",
    "    store = pickle.load(open(f, 'rb'))\n",
    "    f_store = [format_record(item) for item in store]\n",
    "    file_name = os.path.basename(f)\n",
    "    pickle.dump(f_store, open(f\"./data/intermediate/{file_name}\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new features\n",
    "files = [file for file in glob(\"./data/intermediate/*.p\")]\n",
    "\n",
    "for f in files:\n",
    "    store = pickle.load(open(f, 'rb'))\n",
    "    f_store = [create_features(item) for item in store]\n",
    "    file_name = os.path.basename(f)\n",
    "    pickle.dump(f_store, open(f\"./data/processed/{file_name}\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the data\n",
    "files = [file for file in glob(\"./data/processed/*.p\")]\n",
    "full_store = []\n",
    "\n",
    "for f in files:\n",
    "    store = pickle.load(open(f, 'rb'))\n",
    "    full_store.extend(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(full_store)\n",
    "print(df.info())\n",
    "print('')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['brand'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df[['brand', 'price', 'size', 'diff', 'length']]\n",
    "numeric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for extreme values\n",
    "numeric_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare medians by brand\n",
    "numeric_df.groupby('brand')['price', 'diff', 'length'].median().reset_index().rename(\n",
    "    columns={'brand':'Brand', 'price':'Price', 'diff':'Days Listed', 'length':'Title Length'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "df.to_csv('./data/processed/source_data.csv', index=False)\n",
    "numeric_df.to_csv('./data/processed/numeric_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the distributions\n",
    "\n",
    "Use `matplotlib` to plot and analyze the distributions in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/processed/source_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'].plot.hist(bins=12, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_keys = df['brand'].unique()\n",
    "for key in distinct_keys:\n",
    "    plt.figure();\n",
    "    df_subset = df[df.brand==key]\n",
    "    df_subset['price'].plot.hist(bins=20, alpha=0.2, title=key);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of days listed\n",
    "df['diff'].plot.hist(bins=12, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_keys = df['brand'].unique()\n",
    "for key in distinct_keys:\n",
    "    plt.figure();\n",
    "    df_subset = df[df.brand==key]\n",
    "    df_subset['diff'].plot.hist(bins=12, alpha=0.2, title=key);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Distribution of title length\n",
    "df['length'].plot.hist(bins=12, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_df = df[df['sold'] == True]\n",
    "sold_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_df['price'].plot.hist(bins=12, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_keys = sold_df['brand'].unique()\n",
    "for key in distinct_keys:\n",
    "    plt.figure();\n",
    "    df_subset = sold_df[sold_df.brand==key]\n",
    "    df_subset['price'].plot.hist(bins=12, alpha=0.2, title=key);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling \n",
    "\n",
    "Create a basic model to estimate the discount percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/processed/source_data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['brand', 'price', 'size', 'diff', 'length', 'nwt', 'sold']]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listed_df = df[df['sold'] == False]\n",
    "listed_agg = listed_df.groupby('brand')['price', 'diff', 'length'].median().reset_index().rename(\n",
    "    columns={'brand':'Brand', 'price':'Listed Price', 'diff':'Days Listed', 'length':'Title Length'})\n",
    "listed_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_df = df[df['sold'] == True]\n",
    "sold_agg = sold_df.groupby('brand')['price', 'diff', 'length'].median().reset_index().rename(\n",
    "    columns={'brand':'Brand', 'price':'Sold Price', 'diff':'Days Listed', 'length':'Title Length'})\n",
    "sold_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_inner = pd.merge(left=listed_agg[['Brand', 'Listed Price']], \n",
    "                        right=sold_agg[['Brand', 'Sold Price']], \n",
    "                        left_on='Brand', right_on='Brand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_inner['Extra Discount'] = round(1 - (merged_inner['Sold Price'] / merged_inner['Listed Price']), 2) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
